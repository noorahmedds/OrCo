defaults:
  - _self_
  - augmentations: symmetric_auto_augment.yaml
  - wandb: private.yaml
  - override hydra/hydra_logging: disabled
  - override hydra/job_logging: disabled

# disable hydra outputs
hydra:
  output_subdir: null
  run:
    dir: .

name: "(Group CIFAR best_val) supcon (Group CIFAR) supcon (Resnet 12, aa_string: v0-mstd0.5, epochs:300, proj_output_dim:128, simclr_weight:0.1)" # change here for cifar100
method: "supcon"
backbone:
  # name: "resnet18_alice"
  name: "resnet12_nc"
method_kwargs:
  proj_hidden_dim: 2048
  proj_output_dim: 128 # <=====
  temperature: 0.2 # 0.2 with 0.5 we have flatter representation and harder training
  proj_type: "proj"
  apply_infonce: True
  simclr_weight: 0.1
  convex_loss_comb: True
data:
  dataset: fscil_cifar100
  train_path: "./datasets"
  format: "image_folder"
  num_workers: 4
  aa_string: "v0-mstd0.5"
optimizer:
  name: "lars"
  batch_size: 512 #512
  lr: 0.8         #0.4 <===
  classifier_lr: 0.1
  weight_decay: 0.00001
  kwargs:
    momentum: 0.9
    clip_lr: True
    eta: 0.02
    exclude_bias_n_norm: True
scheduler:
  name: "warmup_cosine"
  min_lr: 0
  warmup_start_lr: 0.003
  warmup_epochs: 10
checkpoint:
  enabled: True
  dir: "trained_models"
  frequency: -1 # If frequency is -1 then save the best model only
  keep_prev: False
auto_resume:
  enabled: False

# overwrite PL stuff
max_epochs: 300 #<===
devices: [0]
sync_batchnorm: True
accelerator: "gpu"
strategy: "ddp"
precision: 16
